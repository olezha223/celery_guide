{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Celery\n",
    "\n",
    "Celery - асинхронная распределенная очередь выполнения задач в фоновом режиме, то есть не блокируя выполнение основной программы. Celery - очень гибкий инструмент, вы можете настраивать чуть ли не все аспекты выполнения задач."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2c650bb86d829b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Что такое celery, основные понятия"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d16131083ed2e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Основные компоненты Celery:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ecc1dcf46f617da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) Задача (task) - это базовый элемент Celery, который представляет собой отдельную задачу, которая будет выполнена асинхронно. Каждая задача должна быть определена в отдельном модуле Python, который содержит описание задачи и ее реализацию.\n",
    "\n",
    "2) Очередь (queue) - это очередь задач, которые будут выполнены асинхронно. Каждая задача помещается в очередь и ожидает, когда она будет обработана.\n",
    "\n",
    "3) Worker (worker) - это процесс, который запускает и обрабатывает задачи из очереди. \n",
    "Каждый worker запускается в отдельном процессе и может обрабатывать несколько задач одновременно.\n",
    "\n",
    "4) Брокер (broker) - это посредник между задачами и worker'ами. Он предоставляет очередь задач и хранит информацию о задачах, которые должны быть выполнены. В качестве брокера может выступать RabbitMQ, Redis или другие брокеры сообщений."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4de168ca23c66e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Примеры использования celery в разработке\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff622569d4b9023a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) Сбор продуктовых метрик. Например, вы хотите каждый день собирать метрики по своему продукту, запускать модели машинного обучения и мониторить результаты.\n",
    "\n",
    "2) Отложенное выполнение задач. Например, вы хотите, чтобы в фоне ваше приложение отправило всем пользователем на почту в полночь уведомление о том, что им надо пройти тестирование Иннополис.\n",
    "\n",
    "3) Обработка изображений. Загрузка изображения пользователем на веб-сайт может быть асинхронной. Celery обрабатывает загрузку, ресайз и сохранение изображения в фоновом режиме, не блокируя основной поток веб-сервера и обеспечивая мгновенный отклик пользователю.\n",
    "\n",
    "4) Распределенные вычисления. Celery может быть использован для организации распределенных вычислений, позволяя разбивать задачу на подзадачи и обрабатывать их на разных машинах, значительно сокращая время выполнения."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a8f97efd756ce9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Окей, а что такое эти брокеры сообщений Redis и RabbitMQ?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15f3921b79966865"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Расскажу самую базу про них, но по-хорошему это отдельный доклад про каждый надо пилить.\n",
    "\n",
    "Брокер сообщений представляет собой тип построения архитектуры, при котором элементы системы «общаются» друг с другом с помощью посредника. Благодаря его работе происходит снятие нагрузки с веб-сервисов, так как им не приходится заниматься пересылкой сообщений: всю сопутствующую этому процессу работу он берёт на себя.\n",
    "\n",
    "Можно сказать, что в работе любого брокера сообщений используются две основные сущности: producer (издатель сообщений) и consumer (потребитель/подписчик).\n",
    "\n",
    "Одна сущность занимается созданием сообщений и отправкой их другой сущности-потребителю. В процессе отправки есть ещё серединная точка, которая представляет собой папку файловой системы, где хранятся сообщения, полученные от продюсера.\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://ibb.org.ru/1/fi5sw7\"><img src=\"https://ibb.org.ru/images/2024/12/05/image2dce336435a98e39.png\" alt=\"image2dce336435a98e39.png\" border=\"0\"></a>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b79d7b6d6251248"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если рассмотреть Celery, то в этом случае:\n",
    "\n",
    "1) *Продюсер*: Это часть кода, которая добавляет задачи в очередь Celery. Например, продюсером будет часть кода, которая запускается при оформлении заказа на сайте. Она создает объект задачи Celery, описывающий, что нужно сделать (например, send_order_confirmation, process_payment, ship_order), и отправляет этот объект в брокер сообщений (очередь).\n",
    "\n",
    "2) *Потребитель*: Это  процесс, которые извлекают задачи из очереди и выполняют их. В Celery, потребители называются воркерами. Они постоянно мониторят очередь на наличие новых задач. Когда задача появляется, воркер берет её, выполняет соответствующую функцию (например, send_order_confirmation) и сообщает брокеру о завершении. Воркеры запускаются отдельно от продюсера и могут работать на разных машинах.\n",
    "\n",
    "3) *Очередь сообщений*:  Это промежуточное хранилище задач, связывающее продюсера и потребителя.  Celery может использовать различные брокеры, такие как Redis, RabbitMQ, Amazon SQS и другие.  Брокер  обеспечивает надежное хранение задач, даже если продюсер или потребитель временно недоступны.  В нашем примере мы используем Redis (broker='redis://localhost:6379/0').  Он хранит информацию о задачах (их ID, функцию, аргументы и др.) в своей структуре данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8601ee547665b4eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca35b84f879864d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Допустим, вы написали свое веб-приложение, в котором есть хендлер, который отправляет на почту письма 1 миллиону пользователей. Очевидно, что если это будет выполнять ваш веб-сервер, то он зависнет надолго. Это плохо, ведь он нужен для обработки еще кучи других запросов. Тогда вы хотите сделать так, чтобы на моменте получения информации, что надо отправить письма, ваш скрипт хендлера завершался и передавал свою задачу кому-то там другому, кто на фоне работает. \n",
    "\n",
    "Для этого придумали Celery: он посылает информацию о том, что надо разослать письма, в брокер сообщений, который, в свою очередь помещает это в очередь задач, откуда задачу забирает воркер (сущность - исполнитель). По завершении задачи воркер кидает информацию об этом на результирующий бэкенд. \n",
    "\n",
    "Что мы получили в итоге, внедрив Celery:\n",
    "\n",
    "- наш веб-сервер не нагружен\n",
    "- наш веб-сервер принимает больше полезных запросов\n",
    "- ваша задача разослать письма выполнена\n",
    "- данные о том, как задача выполнена сохранены"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ea9e647ce7533e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Базовое приложение celery "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb9b6c22e6deb843"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запуск окружения и самого celery"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f1fb2b2a0b5c74a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте наконец напишем наше первое приложение. Как говорилось выше, для работы необходим брокер сообщений. Для простоты мы будем использовать **Redis**. Чтобы не затруднять вас в установке этой программы, мы запустим его в Docker-контейнере! Что такое Docker и как его установить можно прочитать в интернете."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "153d571126bbe406"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:18:07.876536800Z",
     "start_time": "2024-12-11T15:18:06.307660500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: celery[redis] in /home/olezha/.local/lib/python3.10/site-packages (5.4.0)\r\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (8.1.7)\r\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (5.1.0)\r\n",
      "Requirement already satisfied: click-repl>=0.2.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (0.3.0)\r\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (1.1.1)\r\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (0.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: kombu<6.0,>=5.3.4 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (5.4.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (2024.2)\r\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (4.2.1)\r\n",
      "Requirement already satisfied: redis!=4.5.5,<6.0.0,>=4.5.2 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (5.2.0)\r\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in /home/olezha/.local/lib/python3.10/site-packages (from click-repl>=0.2.0->celery[redis]) (3.0.48)\r\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in /home/olezha/.local/lib/python3.10/site-packages (from kombu<6.0,>=5.3.4->celery[redis]) (5.3.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->celery[redis]) (1.16.0)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/olezha/.local/lib/python3.10/site-packages (from redis!=4.5.5,<6.0.0,>=4.5.2->celery[redis]) (4.0.3)\r\n",
      "Requirement already satisfied: wcwidth in /home/olezha/.local/lib/python3.10/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery[redis]) (0.2.13)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install celery[redis]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы запустить докер-контейнер, необходимо выполнить команду:\n",
    "\n",
    "```shell\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "Чтобы запустить Celery, необходимо выполнить команду:\n",
    "\n",
    "```shell\n",
    "celery -A <расположение файла в котором находится базовое приложение celery> worker\n",
    "\n",
    "celery -A celery_app worker\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de4b45080339e029"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В юпитер ноутбуке не будет выполняться код, который создает задачи - все задачи, которые мы будем рассматривать в статье уже объявлены в файле **celery_app.py**\n",
    "\n",
    "Код задач будет продублирован в юпитер ноутбуке, но не будет вести ни к чему\n",
    "\n",
    "Код который что-то делает, будет просто запускать задачи"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9324bf1b23591f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Создание приложение, подключение к Redis\n",
    "\n",
    "Мы создаем объект класса Celery, куда мы укажем имя приложения, а также путь до брокера сообщений и бэкенда, куда будет сохраняться вывод задач."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aaf87b700b6f3da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "\n",
    "app = Celery('app', broker='redis_url', backend='redis_url')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:30:01.938912Z",
     "start_time": "2024-12-11T15:30:01.846443500Z"
    }
   },
   "id": "dea104c9a6319dfc",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь мы можем создать первую задачу. Это будет функция, которая возвращает 'Hello World' и выводит в поток вывода 'Hello Celery'.\n",
    "\n",
    "Каждая задача в Celery оборачивается в декоратор task. Потом мы посмотрим, какие полезные аргументы можно прокинуть в этот декоратор.\n",
    "\n",
    "Задачи иногда также называют сообщениями. По сути брокер сообщений - это нечто, что передает сообщения из одной системы в другую. В нашем случае сообщение представляет собой описание задачи: название (уникальный идентификатор), входные параметры, время ожидания, количество повторных попыток и тд.\n",
    "\n",
    "В celery задача является классом. Таким образом, каждый раз, когда вы используете декоратор для функции, чтобы сделать ее задачей, под капотом создается класс. Это означает, что у каждой задачи есть self, к которому добавляется множество атрибутов. Если мы хотим получить доступ к этим атрибутам, то нужно указать параметр bind=True."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b55b1aca828f7bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "@app.task\n",
    "def hello() -> str:\n",
    "    print('Hello Celery!')\n",
    "    return 'Hello World!'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:30:09.503341300Z",
     "start_time": "2024-12-11T15:30:09.487574600Z"
    }
   },
   "id": "d2700c172fb4896c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В целом, это обычная советская функция, которую можно вызвать и декоратор никак не повлияет на ее поведение, но мы то хотим, чтобы все было с использованием Celery.\n",
    "\n",
    "Чтобы вызвать функцию в Celery мы можем использовать методы **delay** и **apply_async**, второй предлагает бОльший функционал, поэтому всегда будем использовать его. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b4ec5d319ad5c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33ac07bc-d897-4b53-bcd9-d352eb452691\n"
     ]
    }
   ],
   "source": [
    "from celery_app import hello\n",
    "\n",
    "result = hello.apply_async()\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:30:13.000888700Z",
     "start_time": "2024-12-11T15:30:12.789557Z"
    }
   },
   "id": "d996f75c6157a915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы получили просто айди задачи в брокере сообщений, то есть данная функция просто помещает нашу задачу в очередь задач в брокере сообщений, который перехватывает ответственность за нее, после чего ее заберет воркер и выполнит. \n",
    "\n",
    "Но куда же делось 'Hello World!' и 'Hello Celery!'? Ответ прост: все логи, то есть результаты принтов лежат в файле **celery.logs**, который мы указали при запуске Celery. \n",
    "\n",
    "Чтобы получить результат выполнения функции, необходимо обратиться к бэкенду, где они лежат. За это отвечает метод **get**. Он будет пытаться забрать из бэкенда результат выполнения задачи, пока не вылетит таймаут. Давайте выполним это"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f93380d14ca76b5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'Hello World!'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:30:34.239914900Z",
     "start_time": "2024-12-11T15:30:34.212706600Z"
    }
   },
   "id": "bb837c193fb7dfa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Еще важный момент, который надо прочувствовать - какой метод будет выполняться долго в вашем коде\n",
    "\n",
    "Для демонстрации допишем функцию hello, чтобы она еще спала 5 секунд"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c55ff3a9a213a853"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import time\n",
    "@app.task\n",
    "def sleepy_hello() -> str:\n",
    "    time.sleep(5)\n",
    "    print('Hello Celery!')\n",
    "    return 'Hello World!'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:30:43.284526900Z",
     "start_time": "2024-12-11T15:30:43.269483800Z"
    }
   },
   "id": "95ce2f410a505c90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Когда вы выполните код ниже, то заметите, что спал именно **get**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15226589f634d6e5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время выполнения apply_async = 0.0\n",
      "время выполнения get = 5.01\n"
     ]
    }
   ],
   "source": [
    "from celery_app import sleepy_hello\n",
    "start_time = time.time()\n",
    "result = sleepy_hello.apply_async()\n",
    "end_time = time.time()\n",
    "print(f'время выполнения apply_async = {round(end_time - start_time, 2)}')\n",
    "\n",
    "start_time = time.time()\n",
    "result.get()\n",
    "end_time = time.time()\n",
    "print(f'время выполнения get = {round(end_time - start_time, 2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:31:15.076727500Z",
     "start_time": "2024-12-11T15:31:09.565213700Z"
    }
   },
   "id": "e84b0edf7a895bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так происходит потому, что apply_async не тратит никаких ресурсов кроме как на добавление задачи в брокер сообщений.\n",
    "\n",
    "В свою очередь get будет требовать у бэкенда результат, но воркер не выполнит код, пока не пройдет 5 секунд, поэтому функция get тоже будет ждать."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ae214647cc14ad9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Погружение в опции запуска задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "626af59ba7f6a098"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Передача аргументов в задачу"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "210d3fc595e4b269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте для начала создадим простую задачу, которая принимает аргументы - сложение двух чисел."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc38d14d1c2e6029"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "@app.task\n",
    "def addition(x: int, y: int) -> int:\n",
    "    return x + y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:31:27.499336400Z",
     "start_time": "2024-12-11T15:31:27.484471800Z"
    }
   },
   "id": "2d9c96c02c5d69a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы прокинуть аргументы при запуске задачи, нужно передать их как кортеж в параметр args"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8f4ce0263d052d7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from celery_app import addition\n",
    "\n",
    "result = addition.apply_async(args=(1, 1))\n",
    "result.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:31:29.542043600Z",
     "start_time": "2024-12-11T15:31:29.472226300Z"
    }
   },
   "id": "7c097930b65cb561"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Отложенный запуск (простая версия)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "774203520425465d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В celery есть очень мощный инструмент для периодизации задач, но есть и что-то более простое. \n",
    "\n",
    "Сейчас мы рассмотрим обратный отсчет до выполнения, он передается как целое количество секунд до запуска функции\n",
    "\n",
    "В чем отличие от обычного **time.sleep** внутри функции? Да просто операция засыпания будет блокировать поток выполнения в воркере, в то время как обратный отсчет - нет. То есть отложенный запуск освобождает воркер от торможения.\n",
    "\n",
    "Количество секунд должно передаваться в аргумент **countdown**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61a40545a6f65de9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "result = addition.apply_async((1, 2), countdown=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:31:49.132278200Z",
     "start_time": "2024-12-11T15:31:49.094276600Z"
    }
   },
   "id": "b095e907840bbce4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:31:54.619224100Z",
     "start_time": "2024-12-11T15:31:49.630486300Z"
    }
   },
   "id": "a6d842ab01a9f27f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно заметить, что поведение очень похоже на случай с time.sleep(5), но могут возникать отличия во времени выполнения даже исполняя один и тот же код несколько раз. Почему?\n",
    "\n",
    "Время в ETA задачах (то есть с отложенным запуском) не является точным временем выполнения этой задачи. Вместо этого это самый ранний момент выполнения этой задачи. Как только наступит время ETA, задача должна дождаться освобождения обработчика. Если обработчик перегружен, то задача может выполниться не сразу. Короче, никто не гарантирует, что выполнится в срок."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "109e1bf6c1a17db9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Повторный запуск задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc8bd8301d26220"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Бывает такое, что ваша задача падает от чего-то непревиденного, например, вы парсите сайт и он радномно вкидывает капчу вам, просто потому что хочет. При этом если через секунду повторить попытку, то все заработает. Или же вы ждете подключения к базе данных. Примеров масса. \n",
    "\n",
    "В таких случаях очень удобно будет сделать так, чтобы ваша задача в случае ошибки еще какое-то время сама пыталась повторить себя. \n",
    "\n",
    "Для этого в celery существует метод **retry**. Для обращения к нему необходимо обратиться к методам таски селери через self, по умолчанию такого нет, поэтому надо передать в декоратор аргумент bind=True. \n",
    "\n",
    "Для примера напишем функцию, которая генерирует ошибку во время выполнения случайным образом, чтобы на какой-то из попыток она заработала. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a07efedd82c9e3fb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "@app.task(bind=True, max_retries=10)\n",
    "def random_error(self) -> str:\n",
    "    import random\n",
    "    try:\n",
    "        if random.randint(1, 20) > 10:\n",
    "            print(1/0)\n",
    "    except ZeroDivisionError as exc:\n",
    "        self.retry(exc=exc, countdown=3)\n",
    "    print(1)\n",
    "    return 'Ура наконец-то выполнилось'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:32:11.780728700Z",
     "start_time": "2024-12-11T15:32:11.766394100Z"
    }
   },
   "id": "12d3354a3cb56d18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так же можно настраивать повтор так, как вам хочется. Вот опции, которые можно добавить:\n",
    "\n",
    "- max_retries (максимальное число попыток)\n",
    "- autoretry_for (кортеж исключений, которые будут автоматически вызывать retry)\n",
    "- countdown (сколько до повторной попытки секунд)\n",
    "\n",
    "Есть и другие, но эти исчерпывают большинство кейсов использования)\n",
    "\n",
    "Давайте посмотрим, как это работает:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bbdc1444d362600"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ура наконец-то выполнилось'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from celery_app import random_error\n",
    "\n",
    "result = random_error.apply_async()\n",
    "result.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:32:34.358130500Z",
     "start_time": "2024-12-11T15:32:34.307365900Z"
    }
   },
   "id": "a95b130c277e8c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если задача не выполнилась после последней попытки, то вылетет исключение, но опять же с основным потоком ничего не случится - ошибка будет на воркере, он внесет данные, что ошибка была получена и забудет об этом."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b25583f0684a4ba5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# задача которая никогда не будет успешно выполнена после ретраев\n",
    "from celery_app import generate_error\n",
    "\n",
    "result = generate_error.apply_async()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:32:42.704558400Z",
     "start_time": "2024-12-11T15:32:42.692417300Z"
    }
   },
   "id": "dc8c7ec45b32781a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "MaxRetriesExceededError",
     "evalue": "Can't retry celery_app.generate_error[af2c2ef8-fa5a-49d4-9d63-2dce704c50eb] args:() kwargs:{}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMaxRetriesExceededError\u001B[0m                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:251\u001B[0m, in \u001B[0;36mAsyncResult.get\u001B[0;34m(self, timeout, propagate, interval, no_ack, follow_parents, callback, on_message, on_interval, disable_sync_subtasks, EXCEPTION_STATES, PROPAGATE_STATES)\u001B[0m\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39madd_pending_result(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait_for_pending\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_on_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mno_ack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_ack\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpropagate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_message\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/asynchronous.py:223\u001B[0m, in \u001B[0;36mAsyncBackendMixin.wait_for_pending\u001B[0;34m(self, result, callback, propagate, **kwargs)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_pending(result, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 223\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_throw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpropagate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:365\u001B[0m, in \u001B[0;36mAsyncResult.maybe_throw\u001B[0;34m(self, propagate, callback)\u001B[0m\n\u001B[1;32m    362\u001B[0m state, value, tb \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    363\u001B[0m     cache[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m], cache[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m], cache\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraceback\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01min\u001B[39;00m states\u001B[38;5;241m.\u001B[39mPROPAGATE_STATES \u001B[38;5;129;01mand\u001B[39;00m propagate:\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_to_remote_traceback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtb\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    367\u001B[0m     callback(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid, value)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:358\u001B[0m, in \u001B[0;36mAsyncResult.throw\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mthrow\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 358\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_ready\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/vine/promises.py:235\u001B[0m, in \u001B[0;36mpromise.throw\u001B[0;34m(self, exc, tb, propagate)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tb \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m (exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m current_exc):\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m--> 235\u001B[0m \u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/vine/utils.py:27\u001B[0m, in \u001B[0;36mreraise\u001B[0;34m(tp, value, tb)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "\u001B[0;31mMaxRetriesExceededError\u001B[0m: Can't retry celery_app.generate_error[af2c2ef8-fa5a-49d4-9d63-2dce704c50eb] args:() kwargs:{}"
     ]
    }
   ],
   "source": [
    "result.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:32:46.055654100Z",
     "start_time": "2024-12-11T15:32:43.457335600Z"
    }
   },
   "id": "659cf1f21b004417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Еще более подробный гайд по повторному запуску вы найдете здесь: \n",
    "http://www.ines-panker.com/2020/10/29/retry-celery-tasks.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "332ea2e78c84770c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Состояния задачи"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbc3e4d68870af33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задачи Celery всегда имеют состояние. Если задача завершила выполнение успешно, ее состоянием является SUCCESS. Если выполнение задачи приводит к исключению, ее состоянием является FAILURE. Celery имеет шесть встроенных состояний:\n",
    "\n",
    "- PENDING (ожидание выполнения или неизвестный идентификатор задачи)\n",
    "\n",
    "- STARTED (задача запущена)\n",
    "\n",
    "- SUCCESS (задача выполнена успешно)\n",
    "\n",
    "- FAILURE (выполнение задачи привело к исключению)\n",
    "\n",
    "- RETRY (задача выполняется повторно)\n",
    "\n",
    "- REVOKED (задача была отозвана)\n",
    "\n",
    "Вместе со статусом задачи идут метаданные. Мы можем добавлять свои кастомные статусы и писать к ним кастомные метаданные и даже ставить встроенные состояния напрямую. Например, если мы имеем задачу, которая состоит из нескольких частей, выполняющихся последовательно, то мы можем сделать новое состояние **PROGRES**, которое будет обозначать, что задача в работе и добавить метаданные к уже имеющимся о том, на каком этапе задача."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e9ce91e101d0b28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте напишем такую задачу, которая бы кастомизировала метаданные и состояния. Для этого используем метод **update_state**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "129e832ac6b44e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "@app.task(bind=True)\n",
    "def long_task(self):\n",
    "    import time\n",
    "    for i in range(5):\n",
    "        # что-то делает в этом месте 2 секунды\n",
    "        time.sleep(2)\n",
    "        self.update_state(state='PROGRESS', meta={\"data\": f\"process {i} done\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:34:53.220531Z",
     "start_time": "2024-12-11T15:34:53.207126600Z"
    }
   },
   "id": "ebcbb9c42d7e3c4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для визуализации того, как меняются статусы у задачи, напишет функцию, которая их мониторит"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361d730ffb179d51"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from celery.result import AsyncResult\n",
    "from celery_app import app\n",
    "def monitor_task(task_id):\n",
    "    task = AsyncResult(task_id, app=app)\n",
    "    while task.state != 'SUCCESS' and task.state != 'FAILURE' and task.state != 'REVOKED':\n",
    "        print(f\"Task state: {task.state}, meta: {task.info}\")\n",
    "        time.sleep(2)\n",
    "    print(f\"Final Task state: {task.state}, result: {task.result}, meta: {task.info}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:36:05.798987600Z",
     "start_time": "2024-12-11T15:36:05.774126300Z"
    }
   },
   "id": "fc92f19de39771a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "А теперь запустим все."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f989d6205f473e15"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task state: PENDING, meta: None\n",
      "Task state: PROGRESS, meta: {'data': 'process 0 done'}\n",
      "Task state: PROGRESS, meta: {'data': 'process 1 done'}\n",
      "Task state: PROGRESS, meta: {'data': 'process 2 done'}\n",
      "Task state: PROGRESS, meta: {'data': 'process 3 done'}\n",
      "Final Task state: SUCCESS, result: None, meta: None\n"
     ]
    }
   ],
   "source": [
    "from celery_app import long_task\n",
    "\n",
    "result = long_task.apply_async()\n",
    "# Мониторим задачу\n",
    "monitor_task(result.id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:36:17.549364800Z",
     "start_time": "2024-12-11T15:36:06.614249300Z"
    }
   },
   "id": "de4fa35197c21502"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как говорилось выше, мы так же можем использовать дефолтные состояния, но изменять в них метаданные\n",
    "\n",
    "Напишем и промониторим задачу, которая будет падать и ставить состояние в FAILURE, также добавим туда кастомизацию из примера выше"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7096533657241d3"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import celery.states as states\n",
    "import random\n",
    "\n",
    "\n",
    "@app.task(bind=True)\n",
    "def complex_task(self, iterations: int = 5):\n",
    "    total_iterations = iterations\n",
    "    for i in range(1, iterations + 1):\n",
    "        time.sleep(2)\n",
    "        self.update_state(\n",
    "            state=\"PROGRES\",\n",
    "            meta={\n",
    "                'current': i,\n",
    "                'progress': int((i / total_iterations) * 100),\n",
    "            }\n",
    "        )\n",
    "        if random.random() < 0.3: # Симуляция непредвиденной ошибки\n",
    "            try:\n",
    "                print(1 / 0)\n",
    "            except ZeroDivisionError:\n",
    "                self.update_state(\n",
    "                    state=states.FAILURE,\n",
    "                    meta={\n",
    "                        'result': ZeroDivisionError,\n",
    "                        'current': i,\n",
    "                        'message': f\"Failed at iteration {i}.\"\n",
    "                    }\n",
    "                )\n",
    "    return {\"status\": \"success\", \"iterations\": iterations}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:38:13.223884100Z",
     "start_time": "2024-12-11T15:38:13.174903700Z"
    }
   },
   "id": "c22fa9d1f8ccf317"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task state: PENDING, meta: None\n",
      "Task state: PROGRES, meta: {'current': 2, 'progress': 40}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception information must include the exception type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/base.py:354\u001B[0m, in \u001B[0;36mBackend.exception_to_python\u001B[0;34m(self, exc)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 354\u001B[0m     exc_type \u001B[38;5;241m=\u001B[39m \u001B[43mexc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mexc_type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'exc_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m result \u001B[38;5;241m=\u001B[39m complex_task\u001B[38;5;241m.\u001B[39mdelay(\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Мониторим задачу\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mmonitor_task\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(result\u001B[38;5;241m.\u001B[39mget())\n",
      "Cell \u001B[0;32mIn[25], line 5\u001B[0m, in \u001B[0;36mmonitor_task\u001B[0;34m(task_id)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmonitor_task\u001B[39m(task_id):\n\u001B[1;32m      4\u001B[0m     task \u001B[38;5;241m=\u001B[39m AsyncResult(task_id, app\u001B[38;5;241m=\u001B[39mapp)\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSUCCESS\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m task\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFAILURE\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m task\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mREVOKED\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTask state: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, meta: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:503\u001B[0m, in \u001B[0;36mAsyncResult.state\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstate\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    476\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"The tasks current state.\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \n\u001B[1;32m    478\u001B[0m \u001B[38;5;124;03m    Possible values includes:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;124;03m            then contains the tasks return value.\u001B[39;00m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 503\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_task_meta\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:442\u001B[0m, in \u001B[0;36mAsyncResult._get_task_meta\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_task_meta\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 442\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_set_cache(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_task_meta\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cache\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/base.py:608\u001B[0m, in \u001B[0;36mBackend.get_task_meta\u001B[0;34m(self, task_id, cache)\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    607\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 608\u001B[0m         meta \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_task_meta_for\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    609\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    610\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/base.py:998\u001B[0m, in \u001B[0;36mBaseKeyValueStoreBackend._get_task_meta_for\u001B[0;34m(self, task_id)\u001B[0m\n\u001B[1;32m    996\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m meta:\n\u001B[1;32m    997\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m: states\u001B[38;5;241m.\u001B[39mPENDING, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m}\n\u001B[0;32m--> 998\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeta\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/base.py:425\u001B[0m, in \u001B[0;36mBackend.decode_result\u001B[0;34m(self, payload)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_result\u001B[39m(\u001B[38;5;28mself\u001B[39m, payload):\n\u001B[0;32m--> 425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeta_from_decoded\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/base.py:421\u001B[0m, in \u001B[0;36mBackend.meta_from_decoded\u001B[0;34m(self, meta)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmeta_from_decoded\u001B[39m(\u001B[38;5;28mself\u001B[39m, meta):\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m meta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mEXCEPTION_STATES:\n\u001B[0;32m--> 421\u001B[0m         meta[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexception_to_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmeta\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresult\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    422\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m meta\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/base.py:356\u001B[0m, in \u001B[0;36mBackend.exception_to_python\u001B[0;34m(self, exc)\u001B[0m\n\u001B[1;32m    354\u001B[0m     exc_type \u001B[38;5;241m=\u001B[39m exc[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexc_type\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 356\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException information must include \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    357\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe exception type\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exc_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m create_exception_cls(\n\u001B[1;32m    360\u001B[0m         exc_type, \u001B[38;5;18m__name__\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Exception information must include the exception type"
     ]
    }
   ],
   "source": [
    "from celery_app import complex_task\n",
    "\n",
    "result = complex_task.delay(5)\n",
    "# Мониторим задачу\n",
    "monitor_task(result.id)\n",
    "\n",
    "print(result.get())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:38:31.744545Z",
     "start_time": "2024-12-11T15:38:27.256949800Z"
    }
   },
   "id": "1f984a09807dba9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ограничение времени выполнения"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2a1f2919359ecfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Иногда подозрительно, что задача работает слишком долго, например, если мы загружаем фотографию. Если это происходит больше 2-3 минут, то точно что-то не так и надо прервать выполнение, чтобы другие задачи могли выполняться без задержек.\n",
    "\n",
    "Как прервать задачу по таймауту в Celery? Надо просто указать параметры\n",
    "\n",
    "1. soft_time_limit - мягкое ограничение, после которого, например, можно кинуть алерт, что что-то не так\n",
    "2. time_limit - жесткое ограничение, после которого задача точно будет завершена со статусом FAILURE\n",
    "\n",
    "Прокидывать эти параметры можно как в аргументы **apply_async**, так и в аргументы декоратора **task**\n",
    "\n",
    "Давайте напишем задачу, которая бы точно падала по таймауту:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f8f9f1387bc304"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from celery.exceptions import SoftTimeLimitExceeded\n",
    "\n",
    "@app.task(bind=True, time_limit=10, soft_time_limit=5)\n",
    "def time_limit_task(self):\n",
    "    try:\n",
    "        time.sleep(6)\n",
    "    except SoftTimeLimitExceeded:\n",
    "        print(\"АААА ЧТО-ТО НЕ ТАК ПОМОГИТЕ СПАСИТЕ\")\n",
    "        self.update_state(state=\"LONG_PROGRES\", meta={\"detail\": \"таска выполняется слишком долго\"})\n",
    "        time.sleep(6)       "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:40:50.591155100Z",
     "start_time": "2024-12-11T15:40:50.563294700Z"
    }
   },
   "id": "1a64a1a439c107ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Запуск задачи и ошибка по таймауту"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2adcd3623e326e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task state: PENDING, meta: None\n",
      "Task state: PENDING, meta: None\n",
      "Task state: PENDING, meta: None\n",
      "Task state: LONG_PROGRES, meta: {'detail': 'таска выполняется слишком долго'}\n",
      "Task state: LONG_PROGRES, meta: {'detail': 'таска выполняется слишком долго'}\n",
      "Final Task state: FAILURE, result: TimeLimitExceeded(10,), meta: TimeLimitExceeded(10,)\n"
     ]
    },
    {
     "ename": "TimeLimitExceeded",
     "evalue": "TimeLimitExceeded(10,)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTimeLimitExceeded\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m result \u001B[38;5;241m=\u001B[39m time_limit_task\u001B[38;5;241m.\u001B[39mapply_async()\n\u001B[1;32m      4\u001B[0m monitor_task(result\u001B[38;5;241m.\u001B[39mid)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:251\u001B[0m, in \u001B[0;36mAsyncResult.get\u001B[0;34m(self, timeout, propagate, interval, no_ack, follow_parents, callback, on_message, on_interval, disable_sync_subtasks, EXCEPTION_STATES, PROPAGATE_STATES)\u001B[0m\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend\u001B[38;5;241m.\u001B[39madd_pending_result(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait_for_pending\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_on_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mno_ack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_ack\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpropagate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_message\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_message\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/backends/asynchronous.py:223\u001B[0m, in \u001B[0;36mAsyncBackendMixin.wait_for_pending\u001B[0;34m(self, result, callback, propagate, **kwargs)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_pending(result, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m--> 223\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_throw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpropagate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:365\u001B[0m, in \u001B[0;36mAsyncResult.maybe_throw\u001B[0;34m(self, propagate, callback)\u001B[0m\n\u001B[1;32m    362\u001B[0m state, value, tb \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    363\u001B[0m     cache[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m], cache[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m], cache\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraceback\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m state \u001B[38;5;129;01min\u001B[39;00m states\u001B[38;5;241m.\u001B[39mPROPAGATE_STATES \u001B[38;5;129;01mand\u001B[39;00m propagate:\n\u001B[0;32m--> 365\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_to_remote_traceback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtb\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    367\u001B[0m     callback(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid, value)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/celery/result.py:358\u001B[0m, in \u001B[0;36mAsyncResult.throw\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mthrow\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 358\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_ready\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthrow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/vine/promises.py:235\u001B[0m, in \u001B[0;36mpromise.throw\u001B[0;34m(self, exc, tb, propagate)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tb \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m (exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m current_exc):\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m--> 235\u001B[0m \u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/vine/utils.py:27\u001B[0m, in \u001B[0;36mreraise\u001B[0;34m(tp, value, tb)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "\u001B[0;31mTimeLimitExceeded\u001B[0m: TimeLimitExceeded(10,)"
     ]
    }
   ],
   "source": [
    "from celery_app import time_limit_task\n",
    "\n",
    "result = time_limit_task.apply_async()\n",
    "monitor_task(result.id)\n",
    "result.get()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:41:03.685650700Z",
     "start_time": "2024-12-11T15:40:52.780680700Z"
    }
   },
   "id": "fe789a5965d646c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "На этом все по значимым аспектам запуска задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ebb55252b69e39c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Настройка воркеров"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74383c50afc224d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В целом, та команда, которой мы запускали celery, она активирует воркера и подключается к брокеру и бэкенду. Мы можем кастомизировать запуск воркеров, а также можем их останавливать.\n",
    "\n",
    "При запуске celery по умолчанию создается один воркер. Этот обработчик является главным процессом (supervisor process), который будет порождать дочерние процессы или потоки, которые в свою очередь будут выполнять задачи. По умолчанию главный обработчик будет создавать дочерние процессы, а не потоки, и он создаст столько одновременных дочерних процессов, сколько ядер у процессора. Главный процесс будет следить за тем, что происходит с задачами и процессами/потоками, но он не будет запускать сами задачи. Эта группа дочерних процессов или потоков, которая ожидает выполнения задач, называется пулом выполнения (execution pool) или пулом потоков (thread pool)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8700f1c0fee9818f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Привязка воркера к очереди"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f077a3ed5e5971c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Очередей можно создать несколько и назвать их тоже можно по разному. По умолчанию есть только одна такая очередь. Все обработчики принимают задачи из одной очереди. Но вы также можете указать несколько таких очередей и назначить конкретные обработчики на определенные очереди. Очередь по умолчанию называется celery.\n",
    "\n",
    "Чтобы создать дополнительную очередь необходимо указать аргумент **-Q** при инициализации воркера, после чего указать название(я). Да, можно пихать задачи в разные очереди."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5da093fe50c29449"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запуск копий воркера в нескольких потоках"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62ab3b2b9fe70de9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это регулируется флагом **--concurency**, дальше указывается число копий воркера."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bc8de68d4c12f9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запуск нескольких воркеров"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fb5533a5b967991"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Когда у нас есть разные задачи, например, мы хотим, чтобы селери собирал продуктовые метрики, рассылал на почту напоминалки и загружал картинки, то разумно разделить эти задачи, чтобы не перегружать оперативную память одного воркера. Тогда мы можем создать нескольких воркеров, чтобы каждый занимался своим делом.\n",
    "\n",
    "Одна команда запускает один воркер, поэтому для запуска трех мы должны три раза прописать команду, задав для каждой свои параметры\n",
    "\n",
    "Чтобы заименовать воркера мы используем аргумент **-n**, после имени воркера идет кастомизация его названия, подробнее можно почитать в документации https://docs.celeryq.dev/en/stable/userguide/workers.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b16f58dff739c729"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "celery -A app.tasks.celery worker -Q queue_aviasales -n worker_aviasales@%h -l INFO --concurrency=8 -f celery.logs\n",
    "& celery -A app.tasks.celery worker -Q queue_flightradar -n worker_flightradar@%h -l INFO --concurrency=1 -f celery.logs\n",
    "& celery -A app.tasks.celery worker -Q queue_influx -n worker_influx@%h -l INFO --concurrency=1 -f celery.logs\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8e263dd4e06842e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Окей, а как задача поймет, кто ее воркер и очередь?\n",
    "\n",
    "Сами задачи не знают, какому воркеру они принадлежат, но они точно знают в какой они очереди. Если не сказано иного, то задача принадлежит главной очереди. Чтобы указать другую надо явно прописать это при объявлении задачи, задав в декораторе **task** аргумент **queue**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24872e5f758565c9"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "@app.task(name=\"some_task\", queue=\"some_queue\")\n",
    "def some_task():\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:42:04.953619500Z",
     "start_time": "2024-12-11T15:42:04.939470300Z"
    }
   },
   "id": "69241799bb78a61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rate limit \n",
    "\n",
    "Еще одна крутая штука, которая позволит не перегружать воркер это **rate_limit**. Данный параметр так же настраивается как аргумент декоратора при объявлении задачи. Он задает максимальную частоту выполнения задачи за определенный период времени. Он не позволит воркеру взять слишком большое количество задач данного типа в единицу времени.\n",
    "\n",
    "Так же его можно настроить, извне, указав название задачи и воркеров."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9139f7099974ecec"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# первый способ\n",
    "@app.task(rate_limit='1/s')\n",
    "def high_load_task():\n",
    "    ...\n",
    "\n",
    "# второй способ\n",
    "app.control.rate_limit('myapp.mytask', '200/m', destination=['celery@worker1.example.com'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:42:05.668554800Z",
     "start_time": "2024-12-11T15:42:05.649128800Z"
    }
   },
   "id": "dc0eb98c36528985"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Интеграция селери в веб-приложение (пример)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "687680bbbd40eec2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### А ТЕПЕРЬ РЕАЛЬНЫЙ ПРИМЕР!!!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "418749c1f3ec50b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сейчас мы напишем простое приложение на FastAPI, в нем будет только одна ручка, которая отправляет реквест на сайт https://github.com/olezha223, будем собирать данные о том, какие у этого пользователя (меня) есть репозитории, после чего данные запишем в json.\n",
    "\n",
    "Делать она это будет с помощью celery, пусть данные запишутся в csv файл"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c81b6ac6100a74"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: fastapi in /home/olezha/.local/lib/python3.10/site-packages (0.115.0)\r\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /home/olezha/.local/lib/python3.10/site-packages (from fastapi) (0.38.6)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/olezha/.local/lib/python3.10/site-packages (from fastapi) (2.9.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/olezha/.local/lib/python3.10/site-packages (from fastapi) (4.12.2)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/olezha/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/olezha/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/olezha/.local/lib/python3.10/site-packages (from starlette<0.39.0,>=0.37.2->fastapi) (4.6.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/olezha/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (3.10)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/olezha/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.3.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/olezha/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install fastapi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:42:10.597312600Z",
     "start_time": "2024-12-11T15:42:09.273936800Z"
    }
   },
   "id": "9cfdffd170413ef3"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "@app.task(bind=True, time_limit=120)\n",
    "def parse_repositories(self, username: str):\n",
    "    try:\n",
    "        url = f\"https://github.com/{username}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        repositories = soup.find_all(\"li\", class_=\"repo-list-item\")\n",
    "        self.update_state(state=\"PROGRES\", meta={\"detail\": \"спарсили репо\"})\n",
    "        repo_list = []\n",
    "        for repository in repositories:\n",
    "            repo_list.append(repository.find(\"a\").text)\n",
    "            self.update_state(state=\"PROGRES\", meta={\"detail\": f'добавили {repository.find(\"a\").text} в список'})\n",
    "\n",
    "        import json\n",
    "        with open(\"repositories.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump({username: repo_list}, file, indent=4, ensure_ascii=False)\n",
    "        self.update_state(state=\"PROGRES\", meta={\"detail\": f'добавили данные в файл'})\n",
    "    except Exception as e:\n",
    "        self.retry(exc=e, countdown=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:42:32.863251800Z",
     "start_time": "2024-12-11T15:42:32.809098100Z"
    }
   },
   "id": "ff7a281202e0799a"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from celery_app import parse_repositories\n",
    "\n",
    "fast_api_app = FastAPI()\n",
    "\n",
    "@fast_api_app.get(\"/get_repositories/{username}\")\n",
    "def get_repositories(username: str) -> str:\n",
    "    task_id = parse_repositories.delay(username)\n",
    "    return task_id.id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:42:54.519691600Z",
     "start_time": "2024-12-11T15:42:53.965864Z"
    }
   },
   "id": "e979ab26b18755f3"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task state: PENDING, meta: None\n",
      "Final Task state: SUCCESS, result: None, meta: None\n"
     ]
    }
   ],
   "source": [
    "# давайте протестируем наш код\n",
    "\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(base_url=\"http://localhost:8000\", app=fast_api_app)\n",
    "response = client.get(\"/get_repositories/olezha223\")\n",
    "assert response.status_code == 200\n",
    "\n",
    "monitor_task(response.json())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:43:04.304639900Z",
     "start_time": "2024-12-11T15:43:02.048505300Z"
    }
   },
   "id": "94112cce1d2a6131"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Мониторинг задач с Flower (докер контейнер + примеры как выглядит) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a537861e7ec79b90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Следить за исполнением задач - важная составляющая работы с ними. Для этого вы можете использовать Flower - это веб-инструмент мониторинга и администрирования Celery в режиме реального времени.\n",
    "\n",
    "Сейчас мы обернем веб-приложение, брокер-сообщений, селери и этот инструмент в докер контейнеры и запустим, посмотрим, как выглядит интерфейс и какие данные мы можем там получить."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "708806d2406e51e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для этой задачи мы создадим отдельную директорию flower и будем писать код в ней"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd3007a9cef0c31e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "\u001B[1A\u001B[1B\u001B[0G\u001B[?25l[+] Running 0/0\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m0.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m1.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m2.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m3.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m4.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m5.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m6.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m7.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m8.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠸\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠼\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.5s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠴\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.6s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠦\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.7s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠧\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.8s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠇\u001B[0m Container redis_for_bot  Stopping                                       \u001B[34m9.9s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠏\u001B[0m Container redis_for_bot  Stopping                                      \u001B[34m10.0s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠋\u001B[0m Container redis_for_bot  Stopping                                      \u001B[34m10.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠙\u001B[0m Container redis_for_bot  Stopping                                      \u001B[34m10.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 0/1\r\n",
      " \u001B[33m⠹\u001B[0m Container redis_for_bot  Stopping                                      \u001B[34m10.3s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l\u001B[34m[+] Running 1/1\u001B[0m\r\n",
      " \u001B[32m✔\u001B[0m Container redis_for_bot  \u001B[32mStopped\u001B[0m                                       \u001B[34m10.4s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[0G\u001B[?25l\u001B[34m[+] Running 1/1\u001B[0m\r\n",
      " \u001B[32m✔\u001B[0m Container redis_for_bot       \u001B[32mRemoved\u001B[0m                                  \u001B[34m10.4s \u001B[0m\r\n",
      " \u001B[33m⠋\u001B[0m Network celery_guide_default  Removin...                                \u001B[34m0.1s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l[+] Running 1/2\r\n",
      " \u001B[32m✔\u001B[0m Container redis_for_bot       \u001B[32mRemoved\u001B[0m                                  \u001B[34m10.4s \u001B[0m\r\n",
      " \u001B[33m⠙\u001B[0m Network celery_guide_default  Removin...                                \u001B[34m0.2s \u001B[0m\r\n",
      "\u001B[?25h\u001B[1A\u001B[1A\u001B[1A\u001B[0G\u001B[?25l\u001B[34m[+] Running 2/2\u001B[0m\r\n",
      " \u001B[32m✔\u001B[0m Container redis_for_bot       \u001B[32mRemoved\u001B[0m                                  \u001B[34m10.4s \u001B[0m\r\n",
      " \u001B[32m✔\u001B[0m Network celery_guide_default  \u001B[32mRemoved\u001B[0m                                   \u001B[34m0.3s \u001B[0m\r\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "# нам надо остановить контейнер, который сейчас ранит наш брокер сообщений\n",
    "! docker-compose down"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T15:45:22.795894900Z",
     "start_time": "2024-12-11T15:45:10.901176900Z"
    }
   },
   "id": "aaa4e48634bcec8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вам необходимо остановить воркеров селери. Для этого просто в терминале, где вы запускали селери нажмите Ctrl+C\n",
    "или же запустите скрипт\n",
    "\n",
    "Теперь выполните в терминале:\n",
    "\n",
    "```shell\n",
    "cd flower\n",
    "docker-compose up -d\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69841a353e347dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### подробнее про созданный файл\n",
    "\n",
    "Мы хотели создать веб-приложение, в котором бы просто была одна ручка, которая запускает задачу парсинга данных с гитхаба, поэтому создаем базовый контейнер для фаст апи, которое будет хоститься на порте 8000.\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  web:\n",
    "    container_name: fast-api\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    command: bash -c \"uvicorn fastapi_app:fast_api_app --host 0.0.0.0 --port 8000\"\n",
    "    volumes:\n",
    "      - .:/app\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    depends_on:\n",
    "      - redis\n",
    "```\n",
    "\n",
    "Напомню, что для селери необходим брокер сообщений, так что мы его как раньше поднимем в контейнере\n",
    "\n",
    "Контейнер с редисом мы оставим такой же, просто поменяем путь до докерфайла и конфига\n",
    "\n",
    "```yaml\n",
    "...\n",
    "  redis:\n",
    "    container_name: redis\n",
    "    build:\n",
    "      context: ../\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_for_report_data:/data\n",
    "      - ../redis.conf:/redis.conf\n",
    "    environment:\n",
    "      REDIS_FOR_BOT_PASSWORD: \"olezha\"\n",
    "    command: [ \"sh\", \"-c\", \"envsubst < /redis.conf > /tmp/processed_redis.conf && redis-server /tmp/processed_redis.conf\" ]\n",
    "```\n",
    "\n",
    "Для селери нужен отдельный контейнер. Мы хотим поднять один воркер, который будет работать с гитхабом, поэтому назовем его worker_github, для практики сделаем 3 его копии, поэтому укажем аргумент --concurrency=3 и пусть логи пишутся в файл celery.logs\n",
    "\n",
    "```yaml\n",
    "...\n",
    "  celery:\n",
    "    build: .\n",
    "    init: true\n",
    "    command: bash -c \"celery -A celery_app worker -n worker_github@%h -l INFO --concurrency=3 -f celery.logs\"\n",
    "    volumes:\n",
    "      - .:/app\n",
    "    depends_on:\n",
    "      - web\n",
    "      - redis\n",
    "```\n",
    "\n",
    "flower всегда запускается командой \n",
    "\n",
    "```shell\n",
    "celery flower \n",
    "```\n",
    "\n",
    "Мы явно укажем порт и ограничение на задачи через аргументы\n",
    "\n",
    "Тогда наш контейнер будет выглядеть так:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "  flower:\n",
    "    image: mher/flower\n",
    "    build: .\n",
    "    command: celery flower --port=8603 --max_tasks=5000\n",
    "    environment:\n",
    "      - CELERY_BROKER_URL=redis://:olezha@redis:6379/0\n",
    "      - FLOWER_PORT=8603\n",
    "    ports:\n",
    "      - 8603:8603\n",
    "    depends_on:\n",
    "      - redis\n",
    "      - celery\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "427c48582c23a7cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### обзор интерфейса flower"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6edbb0e518fc12a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сначала запустим пару задач через Swagger (подробнее про то, что это такое и что такое fast api вы можете найти в лекции Тимура Петрова https://github.com/Palladain/Deep_Python_2024/blob/main/Lectures/Deep_Lecture_10.ipynb\n",
    "\n",
    "Пусть мы хотим спарсить какие репозитории есть у Миши Аникутина (MishaAnikutin) и Олега Швецова (olezha223)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afde263b2b24444f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дальше вам необходимо открыть localhost:8603 и посмотреть, что там будет\n",
    "\n",
    "Вы должны увидеть примерно вот такой интерфейс:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10fcea53ce83d30e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://ibb.org.ru/1/qqM8Zg\"><img src=\"https://ibb.org.ru/images/2024/12/11/image3a3c44d91e7c25f9.png\" alt=\"image3a3c44d91e7c25f9.png\" border=\"0\"></a>\n",
    "\n",
    "<a href=\"https://ibb.org.ru/1/qqQRRK\"><img src=\"https://ibb.org.ru/images/2024/12/11/image5b68e17ed79d798f.png\" alt=\"image5b68e17ed79d798f.png\" border=\"0\"></a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14402c0481127e89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вы можете увидеть, что у нас создался воркер worker_github@7993edc648cf, для которого отображается его статистика: статус (работает/нет), сколько активных воркеров, сколько принятых, упавших, успешных и повторенных задач. \n",
    "\n",
    "Также есть вкладка с тасками, где можно увидеть подробную статистку по ним, какие статусы, какие метаданные, какая статистика по выполнению. \n",
    "\n",
    "Если бы воркеров было больше и задач было несколько тысяч, то вы могли бы видеть вот такую картину: (пример с проекта моего друга по работе)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "febaebee17eb0553"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://ibb.org.ru/1/qqQ5f7\"><img src=\"https://ibb.org.ru/images/2024/12/11/image66d959ac98cb5b90.png\" alt=\"image66d959ac98cb5b90.png\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "<a href=\"https://ibb.org.ru/1/qqQI75\"><img src=\"https://ibb.org.ru/images/2024/12/11/imagee749fa3d685c4428.png\" alt=\"imagee749fa3d685c4428.png\" border=\"0\"></a>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a40e4ab7451665"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таким образом, flower - очень удобный инструмент для мониторинга наших задач в celery."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f100d43310ae90bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Запуск периодических задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dbc2a982c1db81a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вот мы и дошли до очень мощной фичи селери - автоматическая периодизация задач. Для этого мы будем использовать планировщик celery beat. Который запускается при инициализации селери командой\n",
    "\n",
    "```shell\n",
    "celery -A celery_app beat\n",
    "```\n",
    "\n",
    "То есть контейнер будет запускаться командой вида: \n",
    "\n",
    "```shell\n",
    "celery -A celery_app beat \n",
    "& celery -A celery_app worker \n",
    "& ...\n",
    "```\n",
    "\n",
    "Celery beat - это планировщик; он запускает задачи через регулярные промежутки времени, которые затем выполняются доступными рабочими узлами в кластере.\n",
    "\n",
    "По умолчанию записи берутся из параметра beat_schedule, но также можно использовать пользовательские хранилища, например, хранить записи в базе данных SQL.\n",
    "\n",
    "Вы должны убедиться, что для расписания одновременно запущен только один планировщик, в противном случае у вас будут дублироваться задачи. \n",
    "\n",
    "Чтобы добавить задачу в планировщик, вы должны указать в настройках celery через словарь\n",
    "\n",
    "Синтаксис примерно такой:\n",
    "\n",
    "```python\n",
    "app.conf.beat_schedule = {\n",
    "    '...': { # название для регулярной задачи \n",
    "        'task': '...', # путь до задачи\n",
    "        'schedule': ..., # \n",
    "        'args': ... # аргументы задачи\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "Давайте приведем пример. В нем мы скажем селери каждые 10 минут запускать задачу отправки данных в базу, так же указали очередь, в которой все это будет."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73eefdf47f218fec"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from celery.schedules import crontab\n",
    "from celery_app import app\n",
    "app.conf['beat_schedule'] = {\n",
    "    'send_collection_status_to_influx': {\n",
    "        'task': 'send_collection_status_to_influx',\n",
    "        'schedule': crontab(minute='*/10'), \n",
    "        'options': {'queue': 'queue_influx'},\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-11T17:53:53.595525Z",
     "start_time": "2024-12-11T17:53:53.525055900Z"
    }
   },
   "id": "c3637e3ee07db1b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c9822633c31e0d3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
