{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Celery\n",
    "\n",
    "Celery - асинхронная распределенная очередь выполнения задач в фоновом режиме, то есть не блокируя выполнение основной программы. Celery - очень гибкий инструмент, вы можете настраивать чуть ли не все аспекты выполнения задач."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2c650bb86d829b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Что такое celery, основные понятия"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d16131083ed2e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Основные компоненты Celery:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ecc1dcf46f617da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) Задача (task) - это базовый элемент Celery, который представляет собой отдельную задачу, которая будет выполнена асинхронно. Каждая задача должна быть определена в отдельном модуле Python, который содержит описание задачи и ее реализацию.\n",
    "\n",
    "2) Очередь (queue) - это очередь задач, которые будут выполнены асинхронно. Каждая задача помещается в очередь и ожидает, когда ее будет обработана.\n",
    "\n",
    "3) Worker (worker) - это процесс, который запускает и обрабатывает задачи из очереди. \n",
    "Каждый worker запускается в отдельном процессе и может обрабатывать несколько задач одновременно.\n",
    "\n",
    "4) Брокер (broker) - это посредник между задачами и worker'ами. Он предоставляет очередь задач и хранит информацию о задачах, которые должны быть выполнены. В качестве брокера может выступать RabbitMQ, Redis или другие брокеры сообщений."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4de168ca23c66e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Примеры использования celery в разработке\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff622569d4b9023a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) Сбор продуктовых метрик. Например, вы хотите каждый день собирать метрики по своему продукту, запускать модели машинного обучения и мониторить результаты.\n",
    "\n",
    "2) Отложенное выполнение задач. Например, вы хотите, чтобы в фоне ваше приложение отправило всем пользователем на почту в полночь уведомление о том, что им надо пройти тестирование Иннополис.\n",
    "\n",
    "3) Обработка изображений. Загрузка изображения пользователем на веб-сайт может быть асинхронной. Celery обрабатывает загрузку, ресайз и сохранение изображения в фоновом режиме, не блокируя основной поток веб-сервера и обеспечивая мгновенный отклик пользователю.\n",
    "\n",
    "4) Распределенные вычисления. Celery может быть использован для организации распределенных вычислений, позволяя разбивать задачу на подзадачи и обрабатывать их на разных машинах, значительно сокращая время выполнения."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a8f97efd756ce9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Окей, а что такое эти брокеры сообщений Redis и RabbitMQ?\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15f3921b79966865"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Расскажу самую базу про них, но по-хорошему это отдельный доклад про каждый надо пилить.\n",
    "\n",
    "Брокер сообщений представляет собой тип построения архитектуры, при котором элементы системы «общаются» друг с другом с помощью посредника. Благодаря его работе происходит снятие нагрузки с веб-сервисов, так как им не приходится заниматься пересылкой сообщений: всю сопутствующую этому процессу работу он берёт на себя.\n",
    "\n",
    "Можно сказать, что в работе любого брокера сообщений используются две основные сущности: producer (издатель сообщений) и consumer (потребитель/подписчик).\n",
    "\n",
    "Одна сущность занимается созданием сообщений и отправкой их другой сущности-потребителю. В процессе отправки есть ещё серединная точка, которая представляет собой папку файловой системы, где хранятся сообщения, полученные от продюсера.\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://ibb.org.ru/1/fi5sw7\"><img src=\"https://ibb.org.ru/images/2024/12/05/image2dce336435a98e39.png\" alt=\"image2dce336435a98e39.png\" border=\"0\"></a>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b79d7b6d6251248"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если рассмотреть Celery, то в этом случае:\n",
    "\n",
    "1) *Продюсер*: Это часть кода, которая добавляет задачи в очередь Celery. Например, продюсером будет часть кода, которая запускается при оформлении заказа на сайте. Она создает объект задачи Celery, описывающий, что нужно сделать (например, send_order_confirmation, process_payment, ship_order), и отправляет этот объект в брокер сообщений (очередь).\n",
    "\n",
    "2) *Потребитель*: Это  процесс, которые извлекают задачи из очереди и выполняют их. В Celery, потребители называются воркерами. Они постоянно мониторят очередь на наличие новых задач. Когда задача появляется, воркер берет её, выполняет соответствующую функцию (например, send_order_confirmation) и сообщает брокеру о завершении. Воркеры запускаются отдельно от продюсера и могут работать на разных машинах.\n",
    "\n",
    "3) *Очередь сообщений*:  Это промежуточное хранилище задач, связывающее продюсера и потребителя.  Celery может использовать различные брокеры, такие как Redis, RabbitMQ, Amazon SQS и другие.  Брокер  обеспечивает надежное хранение задач, даже если продюсер или потребитель временно недоступны.  В нашем примере мы используем Redis (broker='redis://localhost:6379/0').  Он хранит информацию о задачах (их ID, функцию, аргументы и др.) в своей структуре данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8601ee547665b4eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "---\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ca35b84f879864d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Допустим, вы написали свое веб-приложение, в котором есть хендлер, который отправляет на почту письма 1 миллиону пользователей. Очевидно, что если это будет выполнять ваш веб-сервер, то он зависнет надолго. Это плохо, ведь он нужен для обработки еще кучи других запросов. Тогда вы хотите сделать так, чтобы на моменте получения информации, что надо отправить письма, ваш скрипт хендлера завершался и передавал свою задачу кому-то там другому, кто на фоне работает. \n",
    "\n",
    "Для этого придумали Celery: он посылает информацию о том, что надо разослать письма, в брокер сообщений, который, в свою очередь помещает это в очередь задач, откуда задачу забирает воркер (сущность - исполнитель). По завершении задачи воркер кидает информацию об этом на результирующий бэкенд. \n",
    "\n",
    "Что мы получили в итоге, внедрив Celery:\n",
    "\n",
    "- наш веб-сервер не нагружен\n",
    "- наш веб-сервер принимает больше полезных запросов\n",
    "- ваша задача разослать письма выполнена\n",
    "- данные о том, как задача выполнена сохранены"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ea9e647ce7533e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Базовое приложение celery "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb9b6c22e6deb843"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запуск окружения и самого celery"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f1fb2b2a0b5c74a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте наконец напишем наше первое приложение. Как говорилось выше, для работы необходим брокер сообщений. Для простоты мы будем использовать **Redis**. Чтобы не затруднять вас в установке этой программы, мы запустим его в Docker-контейнере! Что такое Docker и как его установить можно прочитать в интернете."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "153d571126bbe406"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T16:26:35.445001Z",
     "start_time": "2024-12-10T16:26:33.512040100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: celery[redis] in /home/olezha/.local/lib/python3.10/site-packages (5.4.0)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (2024.2)\r\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (1.1.1)\r\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (0.3.1)\r\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (4.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (5.1.0)\r\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (8.1.7)\r\n",
      "Requirement already satisfied: kombu<6.0,>=5.3.4 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (5.4.2)\r\n",
      "Requirement already satisfied: click-repl>=0.2.0 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (0.3.0)\r\n",
      "Requirement already satisfied: redis!=4.5.5,<6.0.0,>=4.5.2 in /home/olezha/.local/lib/python3.10/site-packages (from celery[redis]) (5.2.0)\r\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in /home/olezha/.local/lib/python3.10/site-packages (from click-repl>=0.2.0->celery[redis]) (3.0.48)\r\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in /home/olezha/.local/lib/python3.10/site-packages (from kombu<6.0,>=5.3.4->celery[redis]) (5.3.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->celery[redis]) (1.16.0)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/olezha/.local/lib/python3.10/site-packages (from redis!=4.5.5,<6.0.0,>=4.5.2->celery[redis]) (4.0.3)\r\n",
      "Requirement already satisfied: wcwidth in /home/olezha/.local/lib/python3.10/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery[redis]) (0.2.13)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install celery[redis]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы запустить докер-контейнер, необходимо выполнить команду:\n",
    "\n",
    "```shell\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "Чтобы запустить Celery, необходимо выполнить команду:\n",
    "\n",
    "```shell\n",
    "celery -A <расположение файла в котором находится базовое приложение celery> worker\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de4b45080339e029"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В юпитер ноутбуке не будет выполняться код, который создает задачи - все задачи, которые мы будем рассматривать в статье уже объявлены в файле **celery_app.py**\n",
    "\n",
    "Код задач будет продублирован в юпитер ноутбуке, но не будет вести ни к чему\n",
    "\n",
    "Код который что-то делает, будет просто запускать задачи"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9324bf1b23591f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Создание приложение, подключение к Redis\n",
    "\n",
    "Мы создаем объект класса Celery, куда мы укажем имя приложения, а также путь до брокера сообщений и бэкенда, куда будет сохраняться вывод задач."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aaf87b700b6f3da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "\n",
    "app = Celery('app', broker='redis_url', backend='redis_url')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T16:40:35.892005300Z",
     "start_time": "2024-12-10T16:40:35.656434400Z"
    }
   },
   "id": "dea104c9a6319dfc",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь мы можем создать первую задачу. Это будет функция, которая возвращает 'Hello World' и выводит в поток вывода 'Hello Celery'.\n",
    "\n",
    "Каждая задача в Celery оборачивается в декоратор task. Потом мы посмотрим, какие полезные аргументы можно прокинуть в этот декоратор.\n",
    "\n",
    "Задачи иногда также называют сообщениями. По сути брокер сообщений - это нечто, что передает сообщения из одной системы в другую. В нашем случае сообщение представляет собой описание задачи: название (уникальный идентификатор), входные параметры, время ожидания, количество повторных попыток и тд.\n",
    "\n",
    "В celery задача является классом. Таким образом, каждый раз, когда вы используете декоратор для функции, чтобы сделать ее задачей, под капотом создается класс. Это означает, что у каждой задачи есть self, к которому добавляется множество атрибутов. Если мы хотим получить доступ к этим атрибутам, то нужно указать параметр bind=True."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b55b1aca828f7bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "@app.task\n",
    "def hello() -> str:\n",
    "    print('Hello Celery!')\n",
    "    return 'Hello World!'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T16:46:15.495737800Z",
     "start_time": "2024-12-10T16:46:15.473765300Z"
    }
   },
   "id": "d2700c172fb4896c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В целом, это обычная советская функция, которую можно вызвать и декоратор никак не повлияет на ее поведение, но мы то хотим, чтобы все было с использованием Celery.\n",
    "\n",
    "Чтобы вызвать функцию в Celery мы можем использовать методы **delay** и **apply_async**, второй предлагает бОльший функционал, поэтому всегда будем использовать его. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b4ec5d319ad5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery_app import hello\n",
    "\n",
    "result = hello.apply_async()\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d996f75c6157a915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы получили просто айди задачи в брокере сообщений, то есть данная функция просто помещает нашу задачу в очередь задач в брокере сообщений, который перехватывает ответственность за нее, после чего ее заберет воркер и выполнит. \n",
    "\n",
    "Но куда же делось 'Hello World!' и 'Hello Celery!'? Ответ прост: все логи, то есть результаты принтов лежат в файле **celery.logs**, который мы указали при запуске Celery. \n",
    "\n",
    "Чтобы получить результат выполнения функции, необходимо обратиться к бэкенду, где они лежат. За это отвечает метод **get**. Он будет пытаться забрать из бэкенда результат выполнения задачи, пока не вылетит таймаут. Давайте выполним это"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f93380d14ca76b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result.get()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb837c193fb7dfa3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Еще важный момент, который надо прочувствовать - какой метод будет выполняться долго в вашем коде\n",
    "\n",
    "Для демонстрации допишем функцию hello, чтобы она еще спала 5 секунд"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c55ff3a9a213a853"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "@app.task\n",
    "def sleepy_hello() -> str:\n",
    "    time.sleep(5)\n",
    "    print('Hello Celery!')\n",
    "    return 'Hello World!'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95ce2f410a505c90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Когда вы выполните код ниже, то заметите, что спал именно **get**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15226589f634d6e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "result = sleepy_hello.apply_async()\n",
    "end_time = time.time()\n",
    "print(f'время выполнения apply_async = {round(end_time - start_time, 2)}')\n",
    "\n",
    "start_time = time.time()\n",
    "result.get()\n",
    "end_time = time.time()\n",
    "print(f'время выполнения get = {round(end_time - start_time, 2)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e84b0edf7a895bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так происходит потому, что apply_async не тратит никаких ресурсов кроме как на добавление задачи в брокер сообщений.\n",
    "\n",
    "В свою очередь get будет требовать у бэкенда результат, но воркер не выполнит код, пока не пройдет 5 секунд, поэтому функция get тоже будет ждать."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ae214647cc14ad9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Погружение в опции запуска задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "626af59ba7f6a098"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Передача аргументов в задачу"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "210d3fc595e4b269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте для начала создадим простую задачу, которая принимает аргументы - сложение двух чисел."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc38d14d1c2e6029"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "@app.task\n",
    "def addition(x: int, y: int) -> int:\n",
    "    return x + y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T17:12:30.636797500Z",
     "start_time": "2024-12-10T17:12:30.632413700Z"
    }
   },
   "id": "2d9c96c02c5d69a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы прокинуть аргументы при запуске задачи, нужно передать их как кортеж в параметр args"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8f4ce0263d052d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery_app import addition\n",
    "\n",
    "result = addition.apply_async(args=(1, 1))\n",
    "result.get()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c097930b65cb561"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Отложенный запуск (простая версия)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "774203520425465d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В celery есть очень мощный инструмент для периодизации задач, но есть и что-то более простое. \n",
    "\n",
    "Сейчас мы рассмотрим обратный отсчет до выполнения, он передается как целое количество секунд до запуска функции\n",
    "\n",
    "В чем отличие от обычного **time.sleep** внутри функции? Да просто операция засыпания будет блокировать поток выполнения в воркере, в то время как обратный отсчет - нет. То есть отложенный запуск освобождает воркер от торможения.\n",
    "\n",
    "Количество секунд должно передаваться в аргумент **countdown**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61a40545a6f65de9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = addition.apply_async(countdown=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b095e907840bbce4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result.get()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6d842ab01a9f27f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Можно заметить, что поведение очень похоже на случай с time.sleep(5), но могут возникать отличия во времени выполнения даже исполняя один и тот же код несколько раз. Почему?\n",
    "\n",
    "Время в ETA задачах (то есть с отложенным запуском) не является точным временем выполнения этой задачи. Вместо этого это самый ранний момент выполнения этой задачи. Как только наступит время ETA, задача должна дождаться освобождения обработчика. Если обработчик перегружен, то задача может выполниться не сразу. Короче, никто не гарантирует, что выполнится в срок."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "109e1bf6c1a17db9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Повторный запуск задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc8bd8301d26220"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Бывает такое, что ваша задача падает от чего-то непревиденного, например, вы парсите сайт и он радномно вкидывает капчу вам, просто потому что хочет. При этом если через секунду повторить попытку, то все заработает. Или же вы ждете подключения к базе данных. Примеров масса. \n",
    "\n",
    "В таких случаях очень удобно будет сделать так, чтобы ваша задача в случае ошибки еще какое-то время сама пыталась повторить себя. \n",
    "\n",
    "Для этого в celery существует метод **retry**. Для обращения к нему необходимо обратиться к методам таски селери через self, по умолчанию такого нет, поэтому надо передать в декоратор аргумент bind=True. \n",
    "\n",
    "Для примера напишем функцию, которая генерирует ошибку во время выполнения случайным образом, чтобы на какой-то из попыток она заработала. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a07efedd82c9e3fb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "@app.task(bind=True, max_retries=10)\n",
    "def random_error(self) -> str:\n",
    "    import random\n",
    "    try:\n",
    "        if random.randint(1, 20) > 10:\n",
    "            print(1/0)\n",
    "    except ZeroDivisionError as exc:\n",
    "        self.retry(exc=exc, countdown=3)\n",
    "    print(1)\n",
    "    return 'Ура наконец-то выполнилось'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T17:46:54.885260Z",
     "start_time": "2024-12-10T17:46:54.859731500Z"
    }
   },
   "id": "12d3354a3cb56d18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так же можно настраивать повтор так, как вам хочется. Вот опции, которые можно добавить:\n",
    "\n",
    "- max_retries (максимальное число попыток)\n",
    "- autoretry_for (кортеж исключений, которые будут автоматически вызывать retry)\n",
    "- countdown (сколько до повторной попытки секунд)\n",
    "\n",
    "Есть и другие, но эти исчерпывают большинство кейсов использования)\n",
    "\n",
    "Давайте посмотрим, как это работает:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bbdc1444d362600"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery_app import random_error\n",
    "\n",
    "result = random_error.apply_async()\n",
    "result.get()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a95b130c277e8c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если задача не выполнилась после последней попытки, то вылетет исключение, но опять же с основным потоком ничего не случится - ошибка будет на воркере, он внесет данные, что ошибка была получена и забудет об этом."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b25583f0684a4ba5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# задача которая никогда не будет успешно выполнена после ретраев\n",
    "from celery_app import generate_error\n",
    "\n",
    "result = generate_error.apply_async()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc8c7ec45b32781a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result.get()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "659cf1f21b004417"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Еще более подробный гайд по повторному запуску вы найдете здесь: \n",
    "http://www.ines-panker.com/2020/10/29/retry-celery-tasks.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "332ea2e78c84770c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Состояния задачи"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbc3e4d68870af33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задачи Celery всегда имеют состояние. Если задача завершила выполнение успешно, ее состоянием является SUCCESS. Если выполнение задачи приводит к исключению, ее состоянием является FAILURE. Celery имеет шесть встроенных состояний:\n",
    "\n",
    "- PENDING (ожидание выполнения или неизвестный идентификатор задачи)\n",
    "\n",
    "- STARTED (задача запущена)\n",
    "\n",
    "- SUCCESS (задача выполнена успешно)\n",
    "\n",
    "- FAILURE (выполнение задачи привело к исключению)\n",
    "\n",
    "- RETRY (задача выполняется повторно)\n",
    "\n",
    "- REVOKED (задача была отозвана)\n",
    "\n",
    "Вместе со статусом задачи идут метаданные. Мы можем добавлять свои кастомные статусы и писать к ним кастомные метаданные и даже ставить встроенные состояния напрямую. Например, если мы имеем задачу, которая состоит из нескольких частей, выполняющихся последовательно, то мы можем сделать новое состояние **PROGRES**, которое будет обозначать, что задача в работе и добавить метаданные к уже имеющимся о том, на каком этапе задача."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e9ce91e101d0b28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте напишем такую задачу, которая бы кастомизировала метаданные и состояния. Для этого используем метод **update_state**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "129e832ac6b44e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@app.task(bind=True)\n",
    "def long_task(self):\n",
    "    import time\n",
    "    for i in range(5):\n",
    "        # что-то делает в этом месте 2 секунды\n",
    "        time.sleep(2)\n",
    "        self.update_state(state='PROGRESS', meta={\"data\": f\"process {i} done\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T18:39:12.557099Z",
     "start_time": "2024-12-10T18:39:12.518562400Z"
    }
   },
   "id": "ebcbb9c42d7e3c4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для визуализации того, как меняются статусы у задачи, напишет функцию, которая их мониторит"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "361d730ffb179d51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery.result import AsyncResult\n",
    "def monitor_task(task_id):\n",
    "    task = AsyncResult(task_id, app=app)\n",
    "    while task.state != 'SUCCESS' and task.state != 'FAILURE' and task.state != 'REVOKED':\n",
    "        print(f\"Task state: {task.state}, meta: {task.info}\")\n",
    "        time.sleep(2)\n",
    "    print(f\"Final Task state: {task.state}, result: {task.result}, meta: {task.info}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc92f19de39771a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "А теперь запустим все."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f989d6205f473e15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery_app import long_task\n",
    "\n",
    "result = long_task.delay()\n",
    "# Мониторим задачу\n",
    "monitor_task(result.id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de4fa35197c21502"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как говорилось выше, мы так же можем использовать дефолтные состояния, но изменять в них метаданные\n",
    "\n",
    "Напишем и промониторим задачу, которая будет падать и ставить состояние в FAILURE, также добавим туда кастомизацию из примера выше"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7096533657241d3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import celery.states as states\n",
    "import random\n",
    "\n",
    "\n",
    "@app.task(bind=True)\n",
    "def complex_task(self, iterations: int = 5):\n",
    "    total_iterations = iterations\n",
    "    for i in range(1, iterations + 1):\n",
    "        time.sleep(2)\n",
    "        self.update_state(\n",
    "            state=\"PROGRES\",\n",
    "            meta={\n",
    "                'current': i,\n",
    "                'progress': int((i / total_iterations) * 100),\n",
    "            }\n",
    "        )\n",
    "        if random.random() < 0.3: # Симуляция непредвиденной ошибки\n",
    "            try:\n",
    "                print(1 / 0)\n",
    "            except ZeroDivisionError:\n",
    "                self.update_state(\n",
    "                    state=states.FAILURE,\n",
    "                    meta={\n",
    "                        'current': i,\n",
    "                        'message': f\"Failed at iteration {i}.\"\n",
    "                    }\n",
    "                )\n",
    "    return {\"status\": \"success\", \"iterations\": iterations}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T19:05:36.427508200Z",
     "start_time": "2024-12-10T19:05:36.365912Z"
    }
   },
   "id": "c22fa9d1f8ccf317"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery_app import complex_task\n",
    "\n",
    "result = complex_task.delay()\n",
    "# Мониторим задачу\n",
    "monitor_task(result.id)\n",
    "\n",
    "print(result.get())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f984a09807dba9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ограничение времени выполнения"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2a1f2919359ecfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Иногда подозрительно, что задача работает слишком долго, например, если мы загружаем фотографию. Если это происходит больше 2-3 минут, то точно что-то не так и надо прервать выполнение, чтобы другие задачи могли выполняться без задержек.\n",
    "\n",
    "Как прервать задачу по таймауту в Celery? Надо просто указать параметры\n",
    "\n",
    "1. soft_time_limit - мягкое ограничение, после которого, например, можно кинуть алерт, что что-то не так\n",
    "2. time_limit - жесткое ограничение, после которого задача точно будет завершена со статусом FAILURE\n",
    "\n",
    "Прокидывать эти параметры можно как в аргументы **apply_async**, так и в аргументы декоратора **task**\n",
    "\n",
    "Давайте напишем задачу, которая бы точно падала по таймауту:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f8f9f1387bc304"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery.exceptions import SoftTimeLimitExceeded\n",
    "\n",
    "@app.task(bind=True, time_limit=10, soft_time_limit=5)\n",
    "def time_limit_task(self):\n",
    "    try:\n",
    "        time.sleep(6)\n",
    "    except SoftTimeLimitExceeded:\n",
    "        print(\"АААА ЧТО-ТО НЕ ТАК ПОМОГИТЕ СПАСИТЕ\")\n",
    "        self.update_state(state=\"LONG_PROGRES\", meta={\"detail\": \"таска выполняется слишком долго\"})\n",
    "        time.sleep(6)       "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a64a1a439c107ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Запуск задачи и ошибка по таймауту"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a2adcd3623e326e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from celery_app import time_limit_task\n",
    "\n",
    "result = time_limit_task.apply_async()\n",
    "monitor_task(result.id)\n",
    "result.get()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe789a5965d646c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "На этом все по значимым аспектам запуска задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ebb55252b69e39c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Настройка воркеров"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74383c50afc224d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "В целом, та команда, которой мы запускали celery, она активирует воркера и подключается к брокеру и бэкенду. Мы можем кастомизировать запуск воркеров, а также можем их останавливать.\n",
    "\n",
    "При запуске celery по умолчанию создается один воркер. Этот обработчик является главным процессом (supervisor process), который будет порождать дочерние процессы или потоки, которые в свою очередь будут выполнять задачи. По умолчанию главный обработчик будет создавать дочерние процессы, а не потоки, и он создаст столько одновременных дочерних процессов, сколько ядер у процессора. Главный процесс будет следить за тем, что происходит с задачами и процессами/потоками, но он не будет запускать сами задачи. Эта группа дочерних процессов или потоков, которая ожидает выполнения задач, называется пулом выполнения (execution pool) или пулом потоков (thread pool)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8700f1c0fee9818f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Привязка воркера к очереди"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f077a3ed5e5971c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Очередей можно создать несколько и назвать их тоже можно по разному. По умолчанию есть только одна такая очередь. Все обработчики принимают задачи из одной очереди. Но вы также можете указать несколько таких очередей и назначить конкретные обработчики на определенные очереди. Очередь по умолчанию называется celery.\n",
    "\n",
    "Чтобы создать дополнительную очередь необходимо указать аргумент **-Q** при инициализации воркера, после чего указать название(я). Да, можно пихать задачи в разные очереди."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5da093fe50c29449"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запуск копий воркера в нескольких потоках"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62ab3b2b9fe70de9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это регулируется флагом **--concurency**, дальше указывается число копий воркера."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bc8de68d4c12f9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Запуск нескольких воркеров"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fb5533a5b967991"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Когда у нас есть разные задачи, например, мы хотим, чтобы селери собирал продуктовые метрики, рассылал на почту напоминалки и загружал картинки, то разумно разделить эти задачи, чтобы не перегружать оперативную память одного воркера. Тогда мы можем создать нескольких воркеров, чтобы каждый занимался своим делом.\n",
    "\n",
    "Одна команда запускает один воркер, поэтому для запуска трех мы должны три раза прописать команду, задав для каждой свои параметры\n",
    "\n",
    "Чтобы заименовать воркера мы используем аргумент **-n**, после имени воркера идет кастомизация его названия, подробнее можно почитать в документации https://docs.celeryq.dev/en/stable/userguide/workers.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b16f58dff739c729"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "celery -A app.tasks.celery worker -Q queue_aviasales -n worker_aviasales@%h -l INFO --concurrency=8 -f celery.logs\n",
    "& celery -A app.tasks.celery worker -Q queue_flightradar -n worker_flightradar@%h -l INFO --concurrency=1 -f celery.logs\n",
    "& celery -A app.tasks.celery worker -Q queue_influx -n worker_influx@%h -l INFO --concurrency=1 -f celery.logs\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8e263dd4e06842e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Окей, а как задача поймет, кто ее воркер и очередь?\n",
    "\n",
    "Сами задачи не знают, какому воркеру они принадлежат, но они точно знают в какой они очереди. Если не сказано иного, то задача принадлежит главной очереди. Чтобы указать другую надо явно прописать это при объявлении задачи, задав в декораторе **task** аргумент **queue**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24872e5f758565c9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@app.task(name=\"some_task\", queue=\"some_queue\")\n",
    "def some_task():\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T20:40:59.982977400Z",
     "start_time": "2024-12-10T20:40:59.975774800Z"
    }
   },
   "id": "69241799bb78a61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rate limit \n",
    "\n",
    "Еще одна крутая штука, которая позволит не перегружать воркер это **rate_limit**. Данный параметр так же настраивается как аргумент декоратора при объявлении задачи. Он задает максимальную частоту выполнения задачи за определенный период времени. Он не позволит воркеру взять слишком большое количество задач данного типа в единицу времени.\n",
    "\n",
    "Так же его можно настроить, извне, указав название задачи и воркеров."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9139f7099974ecec"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# первый способ\n",
    "@app.task(rate_limit='1/s')\n",
    "def high_load_task():\n",
    "    ...\n",
    "\n",
    "# второй способ\n",
    "app.control.rate_limit('myapp.mytask', '200/m', destination=['celery@worker1.example.com'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T20:42:00.855904400Z",
     "start_time": "2024-12-10T20:42:00.761150300Z"
    }
   },
   "id": "dc0eb98c36528985"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Интеграция селери в веб-приложение (пример)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "687680bbbd40eec2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### А ТЕПЕРЬ РЕАЛЬНЫЙ ПРИМЕР!!!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "418749c1f3ec50b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сейчас мы напишем простое приложение на FastAPI, в нем будет только одна ручка, которая отправляет реквест на сайт https://github.com/olezha223, будем собирать данные о том, какие у этого пользователя (меня) есть репозитории, после чего данные запишем в json.\n",
    "\n",
    "Делать она это будет с помощью celery, пусть данные запишутся в csv файл"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c81b6ac6100a74"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: fastapi in /home/olezha/.local/lib/python3.10/site-packages (0.115.0)\r\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /home/olezha/.local/lib/python3.10/site-packages (from fastapi) (0.38.6)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/olezha/.local/lib/python3.10/site-packages (from fastapi) (4.12.2)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/olezha/.local/lib/python3.10/site-packages (from fastapi) (2.9.2)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/olezha/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/olezha/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/olezha/.local/lib/python3.10/site-packages (from starlette<0.39.0,>=0.37.2->fastapi) (4.6.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/olezha/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (3.10)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/olezha/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.2.2)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/olezha/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi) (1.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install fastapi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:25.701378600Z",
     "start_time": "2024-12-10T21:21:23.017386400Z"
    }
   },
   "id": "9cfdffd170413ef3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "@app.task(bind=True, time_limit=120)\n",
    "def parse_repositories(self, username: str):\n",
    "    try:\n",
    "        url = f\"https://github.com/{username}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        repositories = soup.find_all(\"li\", class_=\"repo-list-item\")\n",
    "        self.update_state(state=\"PROGRES\", meta={\"detail\": \"спарсили репо\"})\n",
    "        repo_list = []\n",
    "        for repository in repositories:\n",
    "            repo_list.append(repository.find(\"a\").text)\n",
    "            self.update_state(state=\"PROGRES\", meta={\"detail\": f'добавили {repository.find(\"a\").text} в список'})\n",
    "\n",
    "        import json\n",
    "        with open(\"repositories.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump({username: repo_list}, file, indent=4, ensure_ascii=False)\n",
    "        self.update_state(state=\"PROGRES\", meta={\"detail\": f'добавили данные в файл'})\n",
    "    except Exception as e:\n",
    "        self.retry(exc=e, countdown=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff7a281202e0799a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from celery_app import parse_repositories\n",
    "\n",
    "fast_api_app = FastAPI()\n",
    "\n",
    "@fast_api_app.get(\"/get_repositories/{username}\")\n",
    "def get_repositories(username: str) -> str:\n",
    "    task_id = parse_repositories.delay(username)\n",
    "    return task_id.id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-10T22:45:44.772280500Z",
     "start_time": "2024-12-10T22:45:43.950266700Z"
    }
   },
   "id": "e979ab26b18755f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# давайте протестируем наш код\n",
    "\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(base_url=\"http://localhost:8000\", app=fast_api_app)\n",
    "response = client.get(\"/get_repositories/olezha223\")\n",
    "assert response.status_code == 200\n",
    "\n",
    "monitor_task(response.json())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94112cce1d2a6131"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Мониторинг задач с Flower (докер контейнер + примеры как выглядит) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a537861e7ec79b90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Следить за исполнением задач - важная составляющая работы с ними. Для этого вы можете использовать Flower - это веб-инструмент мониторинга и администрирования Celery в режиме реального времени.\n",
    "\n",
    "Сейчас мы обернем веб-приложение, брокер-сообщений, селери и этот инструмент в докер контейнеры и запустим, посмотрим, как выглядит интерфейс и какие данные мы можем там получить."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "708806d2406e51e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для этой задачи мы создадим отдельную директорию flower и будем писать код в ней"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd3007a9cef0c31e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# нам надо остановить контейнер, который сейчас ранит наш брокер сообщений\n",
    "! docker-compose down"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaa4e48634bcec8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь выполните в терминале:\n",
    "\n",
    "```shell\n",
    "cd flower\n",
    "docker-compose up -d\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69841a353e347dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дальше вам необходимо открыть localhost:8603 и посмотреть, что там будет\n",
    "\n",
    "Вы должны увидеть примерно вот такой интерфейс:\n",
    "\n",
    "** картинка flower **\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10fcea53ce83d30e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Запуск периодических задач"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dbc2a982c1db81a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```shell\n",
    "celery -A celery_app beat\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73eefdf47f218fec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
